{"componentChunkName":"component---src-templates-works-work-js","path":"/portfolio-work-7/portfolio-work-6/","result":{"data":{"site":{"siteMetadata":{"title":"Kunjal Panchal"}},"markdownRemark":{"id":"c06ec24f-5974-5d92-8b0b-54d56d4dcc5b","excerpt":"","rawMarkdownBody":"\r\n\r\n<!-- :My journey:<br/>\r\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:6795392367877877760\" height=\"366\" width=\"504\" frameborder=\"0\" allowfullscreen=\"\" title=\"Embedded post\"></iframe> -->","html":"<!-- :My journey:<br/>\n<iframe src=\"https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:6795392367877877760\" height=\"366\" width=\"504\" frameborder=\"0\" allowfullscreen=\"\" title=\"Embedded post\"></iframe> -->","frontmatter":{"title":"Research Scientist/Engineer Intern","date":"July 02, 2023","description":"• Achieved an increase of 4.74 units for Rouge score and 3.60% for Accuracy@1 improvements for few‑shot learning in Flan‑T5 transformer, by expanding their capacity to be able to process more in‑context example within the same context window length through sub‑batching. </br> • Inched closer to finetuning‑like performance through pure in‑context learning (ICL) by 2.16 units of Rouge score and 3% for Accuracy@1 through mesa‑optimization where the transformer acts like an optimizer itself during inference. </br> • Improved the cross‑domain transfer capabilities of a transformer (Flan‑T5) by 1.68 units for Rouge score and 1.3% for Accuracy@1 through incorporating both cross‑ and within domain question‑answer samples within a limited context window length of 512 tokens. </br> • Evaluated and verified the effectiveness of both sub‑batched ICL and mesa‑optimization during inference on both Adobe and public datasets."}}},"pageContext":{"slug":"/portfolio-work-7/portfolio-work-6/"}},"staticQueryHashes":["3649515864","63159454"]}